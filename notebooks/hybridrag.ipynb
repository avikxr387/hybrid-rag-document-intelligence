{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14822332,"sourceType":"datasetVersion","datasetId":9479288}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-12T22:31:14.098656Z","iopub.execute_input":"2026-02-12T22:31:14.098953Z","iopub.status.idle":"2026-02-12T22:31:14.428154Z","shell.execute_reply.started":"2026-02-12T22:31:14.098925Z","shell.execute_reply":"2026-02-12T22:31:14.427035Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/docxfiles/Climate_policy.docx\n/kaggle/input/docxfiles/Baggage Guidelines.pdf\n/kaggle/input/docxfiles/AI_healthcare.docx\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install -q docx2txt\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-12T22:31:14.429732Z","iopub.execute_input":"2026-02-12T22:31:14.430078Z","iopub.status.idle":"2026-02-12T22:31:19.220275Z","shell.execute_reply.started":"2026-02-12T22:31:14.430042Z","shell.execute_reply":"2026-02-12T22:31:19.219448Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"!pip install -q langchain langchain-community sentence-transformers chromadb pypdf python-docx pandas transformers rank_bm25\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-12T22:31:19.221887Z","iopub.execute_input":"2026-02-12T22:31:19.222208Z","iopub.status.idle":"2026-02-12T22:31:36.198385Z","shell.execute_reply.started":"2026-02-12T22:31:19.222179Z","shell.execute_reply":"2026-02-12T22:31:36.197268Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.0/52.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.4/21.4 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.0/220.0 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m78.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-adk 1.22.1 requires google-cloud-bigquery-storage>=2.0.0, which is not installed.\nbigframes 2.26.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ngoogle-adk 1.22.1 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.39.1 which is incompatible.\ngoogle-adk 1.22.1 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\nopentelemetry-exporter-gcp-logging 1.11.0a0 requires opentelemetry-sdk<1.39.0,>=1.35.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\ngoogle-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.47.0 which is incompatible.\ngoogle-colab 1.0.0 requires jupyter-server==2.14.0, but you have jupyter-server 2.12.5 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\ncudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ngradio 5.49.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.5 which is incompatible.\nbigframes 2.26.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\nopentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.39.1 which is incompatible.\nopentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.39.1 which is incompatible.\nopentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\nfastai 2.8.4 requires fastcore<1.9,>=1.8.0, but you have fastcore 1.11.3 which is incompatible.\npylibcudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import os\nimport numpy as np\nfrom pathlib import Path\n\n# Document loaders\nfrom langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader, CSVLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\n\n# Embeddings + Vector DB\nfrom sentence_transformers import SentenceTransformer\nimport chromadb\n\n# BM25\nfrom rank_bm25 import BM25Okapi\n\n# Cross-encoder reranker\nfrom sentence_transformers import CrossEncoder\n\n# Summarization / QA\nfrom transformers import pipeline\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-12T22:31:36.200371Z","iopub.execute_input":"2026-02-12T22:31:36.200643Z","iopub.status.idle":"2026-02-12T22:32:20.226834Z","shell.execute_reply.started":"2026-02-12T22:31:36.200618Z","shell.execute_reply":"2026-02-12T22:32:20.225317Z"}},"outputs":[{"name":"stderr","text":"2026-02-12 22:31:54.836604: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1770935515.058935      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1770935515.128099      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1770935515.685077      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770935515.685122      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770935515.685124      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770935515.685126      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"def load_documents(folder_path):\n    all_docs = []\n    \n    for file in os.listdir(folder_path):\n        path = os.path.join(folder_path, file)\n        \n        if file.endswith(\".pdf\"):\n            loader = PyPDFLoader(path)\n            docs = loader.load()\n        elif file.endswith(\".docx\"):\n            loader = Docx2txtLoader(path)\n            docs = loader.load()\n        elif file.endswith(\".csv\"):\n            loader = CSVLoader(path)\n            docs = loader.load()\n        else:\n            continue\n        \n        for d in docs:\n            d.metadata[\"source\"] = file\n        \n        all_docs.extend(docs)\n    \n    return all_docs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-12T22:32:20.229217Z","iopub.execute_input":"2026-02-12T22:32:20.229491Z","iopub.status.idle":"2026-02-12T22:32:20.236311Z","shell.execute_reply.started":"2026-02-12T22:32:20.229465Z","shell.execute_reply":"2026-02-12T22:32:20.234734Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def split_documents(documents):\n    splitter = RecursiveCharacterTextSplitter(\n        chunk_size=500,\n        chunk_overlap=50\n    )\n    return splitter.split_documents(documents)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-12T22:32:20.238371Z","iopub.execute_input":"2026-02-12T22:32:20.239547Z","iopub.status.idle":"2026-02-12T22:32:20.270053Z","shell.execute_reply.started":"2026-02-12T22:32:20.239504Z","shell.execute_reply":"2026-02-12T22:32:20.268836Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class SemanticIndex:\n    def __init__(self, persist_dir=\"db\"):\n        self.model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n        self.client = chromadb.Client()\n        self.collection = self.client.create_collection(\"docs\")\n    \n    def build(self, docs):\n        texts = [d.page_content for d in docs]\n        metadatas = [d.metadata for d in docs]\n        \n        embeddings = self.model.encode(texts, show_progress_bar=True)\n        \n        ids = [str(i) for i in range(len(texts))]\n        \n        self.collection.add(\n            documents=texts,\n            embeddings=embeddings,\n            metadatas=metadatas,\n            ids=ids\n        )\n    \n    def search(self, query, k=5):\n        q_emb = self.model.encode([query])[0]\n        \n        results = self.collection.query(\n            query_embeddings=[q_emb],\n            n_results=k\n        )\n        \n        docs = []\n        for i in range(len(results[\"documents\"][0])):\n            docs.append({\n                \"text\": results[\"documents\"][0][i],\n                \"metadata\": results[\"metadatas\"][0][i]\n            })\n        \n        return docs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-12T22:32:20.271948Z","iopub.execute_input":"2026-02-12T22:32:20.272365Z","iopub.status.idle":"2026-02-12T22:32:20.290965Z","shell.execute_reply.started":"2026-02-12T22:32:20.272330Z","shell.execute_reply":"2026-02-12T22:32:20.290133Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"class BM25Index:\n    def build(self, docs):\n        self.texts = [d.page_content for d in docs]\n        self.metadatas = [d.metadata for d in docs]\n        tokenized = [t.split() for t in self.texts]\n        self.bm25 = BM25Okapi(tokenized)\n    \n    def search(self, query, k=5):\n        scores = self.bm25.get_scores(query.split())\n        top_k = np.argsort(scores)[-k:][::-1]\n        \n        results = []\n        for idx in top_k:\n            results.append({\n                \"text\": self.texts[idx],\n                \"metadata\": self.metadatas[idx]\n            })\n        \n        return results\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-12T22:32:20.292202Z","iopub.execute_input":"2026-02-12T22:32:20.292603Z","iopub.status.idle":"2026-02-12T22:32:20.312962Z","shell.execute_reply.started":"2026-02-12T22:32:20.292555Z","shell.execute_reply":"2026-02-12T22:32:20.312097Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"class Reranker:\n    def __init__(self):\n        self.model = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n    \n    def rerank(self, query, docs, top_k=3):\n        pairs = [(query, d[\"text\"]) for d in docs]\n        scores = self.model.predict(pairs)\n        \n        ranked = sorted(zip(docs, scores), key=lambda x: x[1], reverse=True)\n        return [r[0] for r in ranked[:top_k]]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-12T22:32:20.313824Z","iopub.execute_input":"2026-02-12T22:32:20.314094Z","iopub.status.idle":"2026-02-12T22:32:20.339057Z","shell.execute_reply.started":"2026-02-12T22:32:20.314062Z","shell.execute_reply":"2026-02-12T22:32:20.337538Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"class HybridRetriever:\n    def __init__(self, semantic_index, bm25_index, reranker):\n        self.semantic = semantic_index\n        self.bm25 = bm25_index\n        self.reranker = reranker\n    \n    def retrieve(self, query, k=5):\n        sem = self.semantic.search(query, k)\n        kw = self.bm25.search(query, k)\n        \n        combined = sem + kw\n        \n        # Remove duplicates\n        unique = []\n        seen = set()\n        for d in combined:\n            if d[\"text\"] not in seen:\n                unique.append(d)\n                seen.add(d[\"text\"])\n        \n        return self.reranker.rerank(query, unique, top_k=k)\n        # return unique[:3]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-12T22:32:20.340278Z","iopub.execute_input":"2026-02-12T22:32:20.340545Z","iopub.status.idle":"2026-02-12T22:32:20.365347Z","shell.execute_reply.started":"2026-02-12T22:32:20.340516Z","shell.execute_reply":"2026-02-12T22:32:20.363806Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"qa_model = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\")\n\ndef answer_question(query, docs):\n    context = \"\\n\".join([d[\"text\"] for d in docs])\n    \n    prompt = f\"\"\"\n    Answer based only on the context.\n\n    Context:\n    {context}\n\n    Question: {query}\n    \"\"\"\n    \n    response = qa_model(prompt, max_length=200)[0][\"generated_text\"]\n    \n    sources = set([d[\"metadata\"][\"source\"] for d in docs])\n    \n    return response, sources\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-12T22:32:20.367510Z","iopub.execute_input":"2026-02-12T22:32:20.367932Z","iopub.status.idle":"2026-02-12T22:32:28.050520Z","shell.execute_reply.started":"2026-02-12T22:32:20.367906Z","shell.execute_reply":"2026-02-12T22:32:28.049844Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e77375064ec04682900cbc30d52e31d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8114c2f3d79a4a80bc9babe001aa6d61"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c540bfc9db7948548b8cb336a49d187e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e382a4821af14fb689b5e1d0fd123e27"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ce985055a5e47619b78ea50e8afbc49"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df32af3f721145b78fdba981546b8fd3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2799fb1ee1514d218b1a4135a1816ed1"}},"metadata":{}},{"name":"stderr","text":"Device set to use cpu\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n\ndef summarize_documents(docs):\n    text = \" \".join([d.page_content for d in docs[:20]])\n    summary = summarizer(text, max_length=200, min_length=50)[0][\"summary_text\"]\n    return summary\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-12T22:32:28.051390Z","iopub.execute_input":"2026-02-12T22:32:28.051625Z","iopub.status.idle":"2026-02-12T22:32:35.447780Z","shell.execute_reply.started":"2026-02-12T22:32:28.051595Z","shell.execute_reply":"2026-02-12T22:32:35.446553Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0641bcb5639644a18b068b39ef004fd1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09359b44bb674a8ea85b38688886cd92"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a722b4c74cb418384eef20fe23c1430"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e975bc880244377bcd77e700b03eb83"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77c537ac4bb7438ea60b95dd42fa4fb4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9358719c858486e87c62398896457bf"}},"metadata":{}},{"name":"stderr","text":"Device set to use cpu\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"def recall_at_k(retrieved_docs, true_source):\n    sources = [d[\"metadata\"][\"source\"] for d in retrieved_docs]\n    return int(true_source in sources)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-12T22:32:35.449552Z","iopub.execute_input":"2026-02-12T22:32:35.449978Z","iopub.status.idle":"2026-02-12T22:32:35.454935Z","shell.execute_reply.started":"2026-02-12T22:32:35.449950Z","shell.execute_reply":"2026-02-12T22:32:35.454017Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def evaluate(query, true_source, semantic, bm25, hybrid):\n    sem_docs = semantic.search(query, k=3)\n    bm_docs = bm25.search(query, k=3)\n    hy_docs = hybrid.retrieve(query)\n    \n    return {\n        \"Semantic\": recall_at_k(sem_docs, true_source),\n        \"BM25\": recall_at_k(bm_docs, true_source),\n        \"Hybrid\": recall_at_k(hy_docs, true_source)\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-12T22:32:35.457615Z","iopub.execute_input":"2026-02-12T22:32:35.458185Z","iopub.status.idle":"2026-02-12T22:32:37.168305Z","shell.execute_reply.started":"2026-02-12T22:32:35.458138Z","shell.execute_reply":"2026-02-12T22:32:37.167187Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"docs = load_documents(\"/kaggle/input/docxfiles\")\nchunks = split_documents(docs)\n\nsemantic = SemanticIndex()\nsemantic.build(chunks)\n\nbm25 = BM25Index()\nbm25.build(chunks)\n\nreranker = Reranker()\nhybrid = HybridRetriever(semantic, bm25, reranker)\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-12T22:32:37.169563Z","iopub.execute_input":"2026-02-12T22:32:37.169967Z","iopub.status.idle":"2026-02-12T22:32:50.169877Z","shell.execute_reply.started":"2026-02-12T22:32:37.169939Z","shell.execute_reply":"2026-02-12T22:32:50.168961Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d23bd16226e41d0b2863ddbabc0a75a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66ad77b5975d4069980d13b80e58c6f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52325efd55304e7d943c9911258e8e3a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f7b19f1baa642f6b24b7c7dfa3da859"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0874eefe0e944dd7bd9eb7cf665ef0a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38ea642761be46838a62d69fb496cbd9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e14969e197a3470f9354defa242b5ff4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb4a74ad7e6147ff9d1e99ff6d0305a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3b80de18dab4bb9b8d1911311dfc3e5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a52da1059bc4402b20b5ad1a14d5694"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f449cb02139048f9867634d2f2464a78"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a47d024a7cff4f1cb207dd9f1df5c19b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/794 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"894b56b04b8c4284bc6f20855a4df01e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6c8bbdb16ac493999bd518f8ed5bc45"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4973c11db63a4dc6b11abbab1d7e1e5e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebde722448444d5aa43cb4ff26115277"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12d324ba20974338bdc07979c39cb28e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/132 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6d32f88063240c992c7c5818218b52e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f73d50b2938475e8e5508013cf76686"}},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"from collections import Counter\n\ndef retrieval_report(retrieved_docs):\n    \"\"\"\n    Shows how many chunks came from each source document\n    \"\"\"\n    sources = [d[\"metadata\"][\"source\"] for d in retrieved_docs]\n    count = Counter(sources)\n    \n    print(\"\\n===== RETRIEVAL REPORT =====\")\n    total = len(retrieved_docs)\n    \n    for src, c in count.items():\n        percent = (c / total) * 100\n        print(f\"{src}: {c} chunks ({percent:.1f}%)\")\n    \n    print(\"Total retrieved chunks:\", total)\n\nfrom collections import Counter\n\ndef relevance_check(results, min_support=2):\n    \"\"\"\n    Returns True if enough chunks support the answer.\n    Prevents hallucination when retrieval is weak.\n    \"\"\"\n    if len(results) == 0:\n        return False\n    \n    sources = [d[\"metadata\"][\"source\"] for d in results]\n    count = Counter(sources)\n    top_count = count.most_common(1)[0][1]\n    \n    return top_count >= min_support\n\ndef format_answer(answer, sources):\n    print(\"\\n===== ANSWER =====\")\n    print(answer)\n    \n    print(\"\\n===== SOURCES =====\")\n    for s in sources:\n        print(\"-\", s)\n\ndef limit_per_source(docs, max_per_source=3):\n    result = []\n    count = {}\n    \n    for d in docs:\n        src = d[\"metadata\"][\"source\"]\n        if count.get(src, 0) < max_per_source:\n            result.append(d)\n            count[src] = count.get(src, 0) + 1\n    \n    return result\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-12T22:32:50.171305Z","iopub.execute_input":"2026-02-12T22:32:50.172203Z","iopub.status.idle":"2026-02-12T22:32:50.180422Z","shell.execute_reply.started":"2026-02-12T22:32:50.172166Z","shell.execute_reply":"2026-02-12T22:32:50.179460Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"query = \"What is the restricted items during air travel\"\n\nresults = hybrid.retrieve(query)\nresults = limit_per_source(results, max_per_source=3)\n\nfor r in results:\n    print(r[\"metadata\"][\"source\"])\nretrieval_report(results)\n\nif not relevance_check(results):\n    print(\"\\n===== ANSWER =====\")\n    print(\"Information not found in the documents.\")\nelse:\n    answer, sources = answer_question(query, results)\n    format_answer(answer, sources)\n\nprint(\"Answer:\", answer)\nprint(\"Sources:\", sources)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-12T22:32:50.181843Z","iopub.execute_input":"2026-02-12T22:32:50.182148Z","iopub.status.idle":"2026-02-12T22:33:03.442752Z","shell.execute_reply.started":"2026-02-12T22:32:50.182123Z","shell.execute_reply":"2026-02-12T22:33:03.441801Z"}},"outputs":[{"name":"stdout","text":"Baggage Guidelines.pdf\nBaggage Guidelines.pdf\nBaggage Guidelines.pdf\n\n===== RETRIEVAL REPORT =====\nBaggage Guidelines.pdf: 3 chunks (100.0%)\nTotal retrieved chunks: 3\n","output_type":"stream"},{"name":"stderr","text":"Both `max_new_tokens` (=256) and `max_length`(=200) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n","output_type":"stream"},{"name":"stdout","text":"\n===== ANSWER =====\nE-cigarettes Lighter Fluid Power Banks Spare Battery Safety Matches Laptop/ Tab Dry Coconut/ Copra Smart Suitcase POWER BANK Power bank, batteries, spare/loose, including lithium metal or lithium ion cells, for portable electronic devices must be carried in cabin baggage only\n\n===== SOURCES =====\n- Baggage Guidelines.pdf\nAnswer: E-cigarettes Lighter Fluid Power Banks Spare Battery Safety Matches Laptop/ Tab Dry Coconut/ Copra Smart Suitcase POWER BANK Power bank, batteries, spare/loose, including lithium metal or lithium ion cells, for portable electronic devices must be carried in cabin baggage only\nSources: {'Baggage Guidelines.pdf'}\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"from collections import Counter\n\nchunk_sources = [c.metadata[\"source\"] for c in chunks]\nprint(Counter(chunk_sources))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-12T22:33:03.443869Z","iopub.execute_input":"2026-02-12T22:33:03.444103Z","iopub.status.idle":"2026-02-12T22:33:03.449298Z","shell.execute_reply.started":"2026-02-12T22:33:03.444083Z","shell.execute_reply":"2026-02-12T22:33:03.447877Z"}},"outputs":[{"name":"stdout","text":"Counter({'Baggage Guidelines.pdf': 6, 'Climate_policy.docx': 3, 'AI_healthcare.docx': 3})\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"test_set = [\n    (\"What will AI do in healthcare?\", \"AI_healthcare.docx\"),\n    (\"Explain restricted items in airport\", \"Baggage Guidelines.pdf\"),\n    (\"What policies are there to protect the climate?\", \"Climate_policy.docx\"),\n]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-12T22:33:03.450741Z","iopub.execute_input":"2026-02-12T22:33:03.451081Z","iopub.status.idle":"2026-02-12T22:33:03.470093Z","shell.execute_reply.started":"2026-02-12T22:33:03.451051Z","shell.execute_reply":"2026-02-12T22:33:03.468682Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"def recall_at_k(retrieved_docs, true_source):\n    sources = [d[\"metadata\"][\"source\"] for d in retrieved_docs]\n    return int(true_source in sources)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-12T22:33:03.471042Z","iopub.execute_input":"2026-02-12T22:33:03.471309Z","iopub.status.idle":"2026-02-12T22:33:03.497859Z","shell.execute_reply.started":"2026-02-12T22:33:03.471248Z","shell.execute_reply":"2026-02-12T22:33:03.496647Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"def evaluate_methods(test_set, semantic, bm25, hybrid):\n    results = {\n        \"Semantic\": 0,\n        \"BM25\": 0,\n        \"Hybrid\": 0\n    }\n    \n    for query, true_src in test_set:\n        sem_docs = semantic.search(query, k=3)\n        bm_docs = bm25.search(query, k=3)\n        hy_docs = hybrid.retrieve(query)\n        \n        results[\"Semantic\"] += recall_at_k(sem_docs, true_src)\n        results[\"BM25\"] += recall_at_k(bm_docs, true_src)\n        results[\"Hybrid\"] += recall_at_k(hy_docs, true_src)\n    \n    total = len(test_set)\n    \n    print(\"\\n===== EVALUATION (Recall@3) =====\")\n    for method in results:\n        score = results[method] / total\n        print(f\"{method}: {score:.2f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-12T22:33:03.499024Z","iopub.execute_input":"2026-02-12T22:33:03.499286Z","iopub.status.idle":"2026-02-12T22:33:03.517235Z","shell.execute_reply.started":"2026-02-12T22:33:03.499262Z","shell.execute_reply":"2026-02-12T22:33:03.515937Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"evaluate_methods(test_set, semantic, bm25, hybrid)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-12T22:33:03.518834Z","iopub.execute_input":"2026-02-12T22:33:03.519287Z","iopub.status.idle":"2026-02-12T22:33:04.105389Z","shell.execute_reply.started":"2026-02-12T22:33:03.519249Z","shell.execute_reply":"2026-02-12T22:33:04.104664Z"}},"outputs":[{"name":"stdout","text":"\n===== EVALUATION (Recall@3) =====\nSemantic: 1.00\nBM25: 0.33\nHybrid: 1.00\n","output_type":"stream"}],"execution_count":22}]}